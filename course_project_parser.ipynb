{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7e74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm_notebook\n",
    "import socks\n",
    "import socket\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb7a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = open('id_films_2.txt')\n",
    "id_films = []\n",
    "for line in dataFile:\n",
    "    id_films.append(line.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c163dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/film/586498/',\n",
       " '/film/899325/',\n",
       " '/film/596025/',\n",
       " '/film/839374/',\n",
       " '/film/1338068/',\n",
       " '/film/1152875/',\n",
       " '/film/1047033/',\n",
       " '/film/1112633/',\n",
       " '/film/1257283/',\n",
       " '/film/2500772/']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_films[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d7c98",
   "metadata": {},
   "source": [
    "парсинг запускался несколько раз для разных списков с фильмами:\n",
    "1. первоначально был взят топ250 -  с одной страницы сайта руками были взяты id фильмов для дальнейшего парсинга рецензий.\n",
    "\n",
    "но! этого показалось мало + разброс отзывов был такой что были в основном положительные.\n",
    "\n",
    "2. далее взялся список из 744 самых худших фильмов (рейтинг 0 - 4.1)\n",
    "\n",
    "но! этого показалось мало... id брались также как в первый раз.\n",
    "\n",
    "3. взялся список из 916 фильмов со \"средним\" рейтингом (4.2 - 6)\n",
    "\n",
    "но! этого показалось мало... id брались также как в первые два раза.\n",
    "\n",
    "4. на сайте таки был найден навигатор, используя который удалось спарсить намного больше id фильмов - 8973 фильма - описан в файле cource_project_parser_ids. в данном случае парсер запускался на каждые 1000 id. далее в файле сохранен запуск для последних 973 фильма.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a1e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_film = []\n",
    "for x in id_films:\n",
    "    id_film.append(int(x.split('/')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94d61e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd450b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_film = id_film[-973:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44f4a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "973"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_film)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b141c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkBot(soup):\n",
    "    if soup.find(lambda tag: tag.name == 'input' and tag.get('class') == ['CheckboxCaptcha-Button']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce2f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkError(soup):\n",
    "    if soup.findAll(lambda tag: tag.name == 'div' and tag.get('class') == ['error-page']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1e0157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPageLinks(id_film, browser):\n",
    "    \n",
    "    sleep_time = 10.0\n",
    "    \n",
    "    time.sleep(sleep_time)\n",
    "    \n",
    "    data_row = []\n",
    "    \n",
    "    page_link = 'https://www.kinopoisk.ru/film/{}/reviews/ord/date/status/all/perpage/200/'.format(id_film)\n",
    "#     response = requests.get(page_link, headers={'User-Agent': UserAgent().chrome})\n",
    "#     html = response.content\n",
    "#     soup = BeautifulSoup(html,'html.parser')\n",
    "#     browser=webdriver.Firefox()\n",
    "    browser.get(page_link)\n",
    "    soup=BeautifulSoup(browser.page_source,'html.parser')\n",
    "    if checkBot(soup):\n",
    "        #print('bot')\n",
    "        return data_row\n",
    "    \n",
    "    if checkError(soup):\n",
    "        #print('error pages')\n",
    "        return data_row\n",
    "    \n",
    "    pages_reviews = []\n",
    "\n",
    "    count_reviews = int(((soup.find(lambda tag: tag.name == 'li' and tag.get('class') == ['all'])).find(lambda tag: tag.name == 'b')).text)\n",
    "    #print(count_reviews)\n",
    "    if count_reviews == 0:\n",
    "        return data_row\n",
    "    elif count_reviews <= 200 and count_reviews > 0:\n",
    "        data_row = getRewiewData(soup)\n",
    "    else:\n",
    "        data_row = getRewiewData(soup)\n",
    "        \n",
    "        count_pages = math.ceil(count_reviews / 200)\n",
    "        #print(count_pages)\n",
    "        for i in range(2, count_pages + 1):\n",
    "            #data_row_temp = []\n",
    "            time.sleep(sleep_time)\n",
    "            page_link = 'https://www.kinopoisk.ru/film/{}/reviews/ord/date/status/all/perpage/200/page/{}/'.format(id_film, i)\n",
    "#             response = requests.get(page_link, headers={'User-Agent': UserAgent().Firefox})\n",
    "#             html = response.content\n",
    "#             soup = BeautifulSoup(html,'html.parser')\n",
    "            browser.get(page_link)\n",
    "            soup=BeautifulSoup(browser.page_source,'html.parser')\n",
    "            if checkBot(soup):\n",
    "                #print('bot')\n",
    "                return data_row\n",
    "            if checkError(soup):\n",
    "                #print('error pages')\n",
    "                return data_row\n",
    "            #data_row_temp = getRewiewData(soup)\n",
    "            data_row.extend(getRewiewData(soup))\n",
    "    return data_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bfd41",
   "metadata": {},
   "source": [
    "почему было принято решение уйти от библиотеки requests - похоже после выполнения домашней работы 5 (по сути данный проект это продолжение данной работы) кинопоиск что-то понял, в этот раз с тем же самым парсером я все время попадал на капчу. поэтому было принято решение использовать selenium и эмулировать работы браузера. изменения в коде были минимальны. а спарсить данных удалось намного больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4987f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRewiewData(soup):\n",
    "    \n",
    "    type_comment = []\n",
    "    date_comment = []\n",
    "    text_comment = []\n",
    "    data_row = []\n",
    "      \n",
    "    type_comment = [d[1] for d in [x.attrs['class'] for x in soup.findAll(lambda tag: tag.name == 'div' and tag.get('itemprop') == 'reviews')]]\n",
    "    date_comment = [x.text for x in soup.findAll(lambda tag: tag.name == 'span' and tag.get('class') == ['date'])]\n",
    "    text_comment = [x.text for x in soup.findAll(lambda tag: tag.name == 'span' and tag.get('class') == ['_reachbanner_'])]\n",
    "    name_movie = [x.text for x in soup.findAll(lambda tag: tag.name == 'a' and tag.get('class') == ['breadcrumbs__link'])]\n",
    "    \n",
    "\n",
    "    for i, j, k in zip(type_comment, date_comment, text_comment):\n",
    "        data_row.append([i, j, k, name_movie[0]])\n",
    "    \n",
    "    return data_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f06066ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(columns=['type_comment', 'date_comment', 'text_comment', 'name_movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c60194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a4c978d5be433fadcef233ffa07235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/973 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exeptions = []\n",
    "browser=webdriver.Firefox()\n",
    "\n",
    "for page_number in tqdm_notebook(id_film):\n",
    "    try:\n",
    "        data_row = getPageLinks(page_number, browser)\n",
    "        df = pd.DataFrame(data_row,columns=['type_comment', 'date_comment', 'text_comment', 'name_movie'])\n",
    "        data_df = data_df.append(df)\n",
    "    except:\n",
    "        exeptions.append(page_number)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9bb7d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_comment</th>\n",
       "      <th>date_comment</th>\n",
       "      <th>text_comment</th>\n",
       "      <th>name_movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad</td>\n",
       "      <td>14 июня 2021 | 20:42</td>\n",
       "      <td>Долгое время являлся большим фанатом фильмов К...</td>\n",
       "      <td>Гуляй, Вася! Свидание на Бали</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>07 мая 2021 | 23:56</td>\n",
       "      <td>Ну сколько раз мир повторял киноделам: если по...</td>\n",
       "      <td>Гуляй, Вася! Свидание на Бали</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>20 апреля 2021 | 11:04</td>\n",
       "      <td>Глубина без грамма серьёзности или обман без г...</td>\n",
       "      <td>Гуляй, Вася! Свидание на Бали</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>20 апреля 2021 | 09:21</td>\n",
       "      <td>Если первую часть можно назвать комедийной мел...</td>\n",
       "      <td>Гуляй, Вася! Свидание на Бали</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "      <td>18 апреля 2021 | 12:48</td>\n",
       "      <td>Среди киноманов уже давно бытует мнение, что п...</td>\n",
       "      <td>Гуляй, Вася! Свидание на Бали</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_comment            date_comment  \\\n",
       "0          bad    14 июня 2021 | 20:42   \n",
       "1          bad     07 мая 2021 | 23:56   \n",
       "2         good  20 апреля 2021 | 11:04   \n",
       "3         good  20 апреля 2021 | 09:21   \n",
       "4          bad  18 апреля 2021 | 12:48   \n",
       "\n",
       "                                        text_comment  \\\n",
       "0  Долгое время являлся большим фанатом фильмов К...   \n",
       "1  Ну сколько раз мир повторял киноделам: если по...   \n",
       "2  Глубина без грамма серьёзности или обман без г...   \n",
       "3  Если первую часть можно назвать комедийной мел...   \n",
       "4  Среди киноманов уже давно бытует мнение, что п...   \n",
       "\n",
       "                      name_movie  \n",
       "0  Гуляй, Вася! Свидание на Бали  \n",
       "1  Гуляй, Вася! Свидание на Бали  \n",
       "2  Гуляй, Вася! Свидание на Бали  \n",
       "3  Гуляй, Вася! Свидание на Бали  \n",
       "4  Гуляй, Вася! Свидание на Бали  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8155b9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 28345 entries, 0 to 111\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   type_comment  28345 non-null  object\n",
      " 1   date_comment  28345 non-null  object\n",
      " 2   text_comment  28345 non-null  object\n",
      " 3   name_movie    28345 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b048097",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments_add_9.json', 'w', encoding='utf-8') as file:\n",
    "    data_df.to_json(file, force_ascii=False, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26aaac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92c21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e420ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8dc243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676ff37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc9063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90831a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ce948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
